{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tacotron2 + WaveGlow í•œêµ­ì–´ TTS ìµœì í™”ë¥¼ ìœ„í•œ í•„ìˆ˜ ì „ì²˜ë¦¬ ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ì •ë¦¬í•œ ë‚´ìš©\n",
    "1. í…ìŠ¤íŠ¸ ì •ì œ, ìì†Œë¶„ë¦¬, vocab ìƒì„± ë° tokenize\n",
    "2. ìŒì„± ë°ì´í„° ì „ì²˜ë¦¬\n",
    "3. ë©œìŠ¤í™íŠ¸ë¡œê·¸ë¨ ë³€í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install librosa numpy noisereduce jamo webrtcvad matplotlib sox sentencepiece\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬\n",
    "- ì •ì œ\n",
    "- ìì†Œë¶„ë¦¬ (ìŒì†Œ ë‹¨ìœ„ ë³€í™˜)\n",
    "- vocab ìƒì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### í…ìŠ¤íŠ¸ ì •ì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_numbers(text):\n",
    "    \"\"\"ìˆ«ìë¥¼ í•œê¸€ ë°œìŒìœ¼ë¡œ ë³€í™˜\"\"\"\n",
    "    num_dict = {\n",
    "        \"0\": \"ì˜\", \"1\": \"ì¼\", \"2\": \"ì´\", \"3\": \"ì‚¼\", \"4\": \"ì‚¬\",\n",
    "        \"5\": \"ì˜¤\", \"6\": \"ìœ¡\", \"7\": \"ì¹ \", \"8\": \"íŒ”\", \"9\": \"êµ¬\"\n",
    "    }\n",
    "    return \"\".join(num_dict.get(c, c) for c in text)\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"í…ìŠ¤íŠ¸ ì •ì œ\"\"\"\n",
    "    text = text.lower()  # ì†Œë¬¸ìë¡œ ë³€í™˜\n",
    "    text = re.sub(r'[^ê°€-í£0-9\\s,.!?]', '', text)  # í•œê¸€, ìˆ«ì, ê³µë°±, êµ¬ë‘ì ë§Œ ìœ ì§€\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # ì—°ì†ëœ ê³µë°± ì œê±°\n",
    "    text = normalize_numbers(text)  # ìˆ«ì ë³€í™˜\n",
    "    return text\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "sample_text = \"100cmì§œë¦¬ 2024ë…„ ëª¨ë¸ì…ë‹ˆë‹¤!\"\n",
    "print(clean_text(sample_text))  # \"ì¼ê³µê³µ ì„¼í‹°ë¯¸í„°ì§œë¦¬ ì´ê³µì´ì‚¬ë…„ ëª¨ë¸ì…ë‹ˆë‹¤!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ìì†Œ ë¶„ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jamo\n",
    "\n",
    "def split_jaso(text):\n",
    "    \"\"\"í•œê¸€ì„ ìì†Œ ë‹¨ìœ„ë¡œ ë¶„ë¦¬\"\"\"\n",
    "    return \" \".join(jamo.hangul_to_jamo(text))\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "print(split_jaso(\"ì•ˆë…•í•˜ì„¸ìš”\"))  # \"ã…‡ã…ã„´ ã„´ã…•ã…‡ ã…ã… ã……ã…” ã…‡ã…›\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenizer ë° Vocab ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "# í•™ìŠµìš© ì½”í¼ìŠ¤ ì €ì¥\n",
    "corpus_texts = [\"ì•ˆë…•í•˜ì„¸ìš”\", \"ë°˜ê°‘ìŠµë‹ˆë‹¤\", \"ì´ ëª¨ë¸ì€ TTS ì‹œìŠ¤í…œì…ë‹ˆë‹¤.\"]\n",
    "with open(\"corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in corpus_texts:\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "# SentencePiece ëª¨ë¸ í•™ìŠµ\n",
    "spm.SentencePieceTrainer.train(input=\"corpus.txt\", model_prefix=\"tokenizer\", vocab_size=500, model_type=\"bpe\")\n",
    "\n",
    "# Tokenizer ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"tokenizer.model\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "print(sp.encode_as_pieces(\"ì´ ëª¨ë¸ì€ TTS ì‹œìŠ¤í…œì…ë‹ˆë‹¤.\"))  # ì˜ˆ: ['â–ì´', 'â–ëª¨ë¸ì€', 'â–TTS', 'â–ì‹œìŠ¤í…œì…ë‹ˆë‹¤']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) ìŒì„± ë°ì´í„° ì „ì²˜ë¦¬\n",
    "- ìƒ˜í”Œë§ ë ˆì´íŠ¸ ë³€í™˜\n",
    "- ë¬´ìŒ ì œê±°\n",
    "- ë³¼ë¥¨ ì •ê·œí™”\n",
    "- ì¡ìŒ ì œê±°\n",
    "- ë°ì´í„° ê¸¸ì´ í†µì¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ìƒ˜í”Œë§ ë ˆì´íŠ¸ ë³€í™˜ (16kHz -> 22.05kHz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "# ìŒì„± ë°ì´í„° ë¡œë“œ\n",
    "y, sr = librosa.load(\"audio.wav\", sr=16000)\n",
    "\n",
    "# 22050Hzë¡œ ë³€í™˜\n",
    "y_resampled = librosa.resample(y, orig_sr=sr, target_sr=22050)\n",
    "\n",
    "# ì €ì¥\n",
    "librosa.output.write_wav(\"resampled_audio.wav\", y_resampled, 22050)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ë¬´ìŒ ì œê±°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.effects\n",
    "\n",
    "y, sr = librosa.load(\"resampled_audio.wav\", sr=22050)\n",
    "\n",
    "# ë¬´ìŒ ì œê±°\n",
    "y_trimmed, _ = librosa.effects.trim(y, top_db=20)\n",
    "\n",
    "librosa.output.write_wav(\"trimmed_audio.wav\", y_trimmed, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ë³¼ë¥¨ ì •ê·œí™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def normalize_audio(y):\n",
    "    return y / np.max(np.abs(y))  # ìµœëŒ€ ì§„í­ì„ 1ë¡œ ì •ê·œí™”\n",
    "\n",
    "y, sr = librosa.load(\"trimmed_audio.wav\", sr=22050)\n",
    "y_norm = normalize_audio(y)\n",
    "\n",
    "librosa.output.write_wav(\"normalized_audio.wav\", y_norm, sr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ì¡ìŒ ì œê±°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import noisereduce as nr\n",
    "\n",
    "y, sr = librosa.load(\"normalized_audio.wav\", sr=22050)\n",
    "\n",
    "# ì¡ìŒ ì œê±°\n",
    "y_denoised = nr.reduce_noise(y=y, sr=sr)\n",
    "\n",
    "librosa.output.write_wav(\"denoised_audio.wav\", y_denoised, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ìƒì„± ë° ì‹œê°í™”\n",
    "- ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ë³€í™˜\n",
    "- ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ë³€í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y, sr = librosa.load(\"denoised_audio.wav\", sr=22050)\n",
    "\n",
    "# ë©œìŠ¤í™íŠ¸ë¡œê·¸ë¨ ë³€í™˜\n",
    "mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=80, hop_length=256, win_length=1024, fmax=8000)\n",
    "\n",
    "# ë¡œê·¸ ë³€í™˜\n",
    "log_mel_spec = librosa.power_to_db(mel_spec, ref=np.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(log_mel_spec, sr=sr, x_axis='time', y_axis='mel')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Mel Spectrogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ” ì •ë¦¬: ì „ì²´ ì „ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤\n",
    "\n",
    "##### âœ… í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬\n",
    "- í…ìŠ¤íŠ¸ ì •ì œ (clean_text())\n",
    "- ìì†Œ ë¶„ë¦¬ (split_jaso())\n",
    "- í† í¬ë‚˜ì´ì € (sentencepiece í™œìš©)\n",
    "\n",
    "##### âœ… ìŒì„± ë°ì´í„° ì „ì²˜ë¦¬\n",
    "- ìƒ˜í”Œë§ ë ˆì´íŠ¸ í†µì¼ (16kHz â†’ 22.05kHz)\n",
    "- ë¬´ìŒ ì œê±° (librosa.effects.trim())\n",
    "- ë³¼ë¥¨ ì •ê·œí™”\n",
    "- ì¡ìŒ ì œê±° (noisereduce í™œìš©)\n",
    "\n",
    "##### âœ… ë©œìŠ¤í™íŠ¸ë¡œê·¸ë¨ ë³€í™˜ ë° ì‹œê°í™”\n",
    "- 80ê°œ Mel í•„í„° ì‚¬ìš©\n",
    "- Hop length 256, Win length 1024\n",
    "- fmax=8000 ì„¤ì •\n",
    "- ë¡œê·¸ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ë³€í™˜ í›„ ì‹œê°í™”"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
